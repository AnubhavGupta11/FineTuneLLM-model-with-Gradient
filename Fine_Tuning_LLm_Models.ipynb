{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e6CTeeHcdoZ",
        "outputId": "4fc3e2f9-e73b-420d-f777-f6ab5066799c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradientai\n",
            "  Downloading gradientai-1.7.0-py3-none-any.whl (270 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.4/270.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum>=3.1.11 (from gradientai)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<2.0.0,>=1.10.5 (from gradientai)\n",
            "  Downloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0,>=1.10.5->gradientai) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->gradientai) (1.16.0)\n",
            "Installing collected packages: aenum, pydantic, gradientai\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.0\n",
            "    Uninstalling pydantic-2.6.0:\n",
            "      Successfully uninstalled pydantic-2.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aenum-3.1.15 gradientai-1.7.0 pydantic-1.10.14\n"
          ]
        }
      ],
      "source": [
        "!pip install gradientai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GRADIENT_WORKSPACE_ID']='32b6c355-71bd-4965-9660-198601c92233_workspace'\n",
        "os.environ['GRADIENT_ACCESS_TOKEN']='gqbgvDEDlvdWklA2n5vmp1eeDpSwVTqz'"
      ],
      "metadata": {
        "id": "SU3cUwwacjww"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gradientai import Gradient\n",
        "\n",
        "\n",
        "def main():\n",
        "    gradient = Gradient()\n",
        "\n",
        "    base_model = gradient.get_base_model(base_model_slug=\"nous-hermes2\")\n",
        "\n",
        "    new_model_adapter = base_model.create_model_adapter(\n",
        "        name=\"Newmodel\"\n",
        "    )\n",
        "    print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
        "\n",
        "\n",
        "    sample_query = \"### Instruction: Who is Anubhav? \\n\\n ### Response:\"\n",
        "    print(f\"Asking: {sample_query}\")\n",
        "    ## Before Finetuning\n",
        "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "    print(f\"Generated(before fine tuning): {completion}\")\n",
        "\n",
        "    samples=[\n",
        "        {\"inputs\":\"### Instruction: Who is Anubhav? \\n\\n### Response: Anubhav is a popular mentor and youtuber who uploads content on Data Science,AI And LLM in his channel Anubhav11\"},\n",
        "        {\"inputs\":\"### Instruction: Who is this person named Anubhav? \\n\\n### Response: Anubhav Like Data Science And AI And makes content in git and he is also a mentor\"},\n",
        "        {\"inputs\":\"### Instruction: What do you know about Anubhav? \\n\\n### Response: Anubhav is a popular creator who specializes in the field of Data Science and his channel name is Anubhav11\"},\n",
        "        {\"inputs\":\"### Instruction: Can you tell me about Anubhav? \\n\\n### Response: Anubhav is a DS,content creator,and a creator who loves Data Science And AI and LLM's\"}\n",
        "    ]\n",
        "\n",
        "    ## Lets define parameters for finetuning\n",
        "    num_epochs=3\n",
        "    count=0\n",
        "    while count<num_epochs:\n",
        "      print(f\"Fine tuning the model with iteration {count + 1}\")\n",
        "      new_model_adapter.fine_tune(samples=samples)\n",
        "      count=count+1\n",
        "\n",
        "    #after fine tuning\n",
        "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "    print(f\"Generated(after fine tuning): {completion}\")\n",
        "    new_model_adapter.delete()\n",
        "    gradient.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U5D6rx6deHY",
        "outputId": "a42b0746-f996-45ba-e98d-41fb729faab7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created model adapter with id 627442c8-df58-42bd-89a4-d35718d8a7d6_model_adapter\n",
            "Asking: ### Instruction: Who is Anubhav? \n",
            "\n",
            " ### Response:\n",
            "Generated(before fine tuning):  Anubhav is a name of Indian origin that means \"aware, conscious, or experienced\". It can be used as a given name or a surname.\n",
            "Fine tuning the model with iteration 1\n",
            "Fine tuning the model with iteration 2\n",
            "Fine tuning the model with iteration 3\n",
            "Generated(after fine tuning):  Anubhav is a popular mentor and creator who specializes in the field of Data Science and his channel name is Anubhav11. He is known for his amazing content and his way of teaching which is very easy to understand.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uifyewQ9dmjs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}